{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 09:39:19.634520: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-09 09:39:19.975200: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-09 09:39:19.976681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-09 09:39:21.741138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import regex as re\n",
    "import seaborn as sns\n",
    "from prepocessing import clean_text_df\n",
    "from stempel import StempelStemmer\n",
    "import regex as re\n",
    "from joblib import load\n",
    "from keras import models\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from models import data_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('files/dataset_5_preprocessed.csv', index_col='id', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|          | 0/11368252 [00:00<?, ?bytes/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 11368252/11368252 [00:07<00:00, 1548424.08bytes/s]\n"
     ]
    }
   ],
   "source": [
    "stemmer = StempelStemmer.polimorf()\n",
    "df = clean_text_df(df,stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/'\n",
    "vectorizer = load(path + 'tfidf.pkl')\n",
    "selector = load(path + 'selector.pkl')\n",
    "nn_c = models.load_model(path + 'nn_classifier.h5') \n",
    "enc = load(path + 'encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                643200    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 645825 (2.46 MB)\n",
      "Trainable params: 645825 (2.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/hombresabio/AI/Climate Project/Binary Classification/tsne.ipynb Cell 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hombresabio/AI/Climate%20Project/Binary%20Classification/tsne.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m data_vectorization(df, vectorizer, selector, enc)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hombresabio/AI/Climate%20Project/Binary%20Classification/tsne.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m layers \u001b[39m=\u001b[39m nn_c\u001b[39m.\u001b[39mlayers\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hombresabio/AI/Climate%20Project/Binary%20Classification/tsne.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m new_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential(layers[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/AI/Climate Project/Binary Classification/models.py:73\u001b[0m, in \u001b[0;36mdata_vectorization\u001b[0;34m(data, vectorizer, selector, enc)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     data_x \u001b[39m=\u001b[39m data\n\u001b[0;32m---> 73\u001b[0m text_x \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mtransform(data_x[\u001b[39m'\u001b[39;49m\u001b[39mtext_title\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     74\u001b[0m text_x \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mtransform(text_x)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     75\u001b[0m features_encoded \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mtransform(data_x[[\u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdepartment\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m]])\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_title'"
     ]
    }
   ],
   "source": [
    "data = data_vectorization(df, vectorizer, selector, enc)\n",
    "layers = nn_c.layers\n",
    "new_model = tf.keras.models.Sequential(layers[:-1])\n",
    "x_values, y_values = data\n",
    "x_values.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 7546)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 09:15:38.370059: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 132447392 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "x_values = new_model(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 2194 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 2194 samples in 0.125s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2194\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2194\n",
      "[t-SNE] Computed conditional probabilities for sample 2194 / 2194\n",
      "[t-SNE] Mean sigma: 0.013655\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.370224\n",
      "[t-SNE] KL divergence after 5000 iterations: 0.131341\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2,perplexity=50,n_iter=25000, verbose=1, random_state=123)\n",
    "v = tsne.fit_transform(x_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.DataFrame()\n",
    "df_tsne[\"class\"] = y_values\n",
    "df_tsne[\"x\"] = v[:,0]\n",
    "df_tsne[\"y\"] = v[:,1]\n",
    "df_tsne[\"text\"] = df[\"text\"]\n",
    "df_tsne[\"id\"] = df.index\n",
    "df_tsne.to_csv(\"tsne.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a2be30295172717884411af564ad630433b1e83c9c4d3e12b02d716b3136821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
