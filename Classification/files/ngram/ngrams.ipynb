{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 08:23:49.772484: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-04 08:23:49.818484: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-04 08:23:50.783759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ngrams import save_rest_ngrams, lemmatizer, get_eco_vocab\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['politic', 'industry',\t'energy', 'klimat', 'water', 'other', 'car']\n",
    "for topic in topics:\n",
    "    df = pd.read_csv(f\"../../{topic}.csv\", index_col='id')\n",
    "    save_rest_ngrams(df, 100, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirpath, folders, files in os.walk(\"topics\"):\n",
    "    file_list = [os.path.join(dirpath, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics/car_grams.csv\n",
      "topics/other_grams.csv\n",
      "topics/water_grams.csv\n",
      "topics/klimat_grams.csv\n",
      "topics/energy_grams.csv\n",
      "topics/industry_grams.csv\n",
      "topics/politic_grams.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "data = []\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df['origin'] = re.search(\"/(.*)_\", file).group(1)\n",
    "    df.drop(columns='count', inplace=True)\n",
    "    data.append(df)\n",
    "df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.groupby(\"phrase\")['origin'].nunique()\n",
    "assert len(categories[categories > 1]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['phrase'].duplicated()]\n",
    "df.to_csv(\"ngrams.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
