{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from classify import data_pipeline, eco_selector\n",
        "from resources.get_data import get_current_data\n",
        "from resources.setup import get_setup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validator(df):\n",
        "    df = df.drop_duplicates()\n",
        "    df = df[~df['text'].isna()]\n",
        "    if 'vectorized' in df.columns.values:\n",
        "        df = df.drop(columns=['vectorized'])\n",
        "    if df.index.duplicated().any():\n",
        "        print(\"Duplicated index!!!\")\n",
        "        df = df.reset_index()\n",
        "        df = df.drop(columns = ['id'])\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    elif 'id' not in df.columns.values:\n",
        "        df = df.reset_index()\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    print(f\"Found {len(df)} files\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rzepa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'rzepa'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_final = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wyborcza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'wyborcza'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_final = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gazeta Polska Codziennie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'gpc'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polityka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'polityka'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Small Corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dorzeczy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "corp = 'dorzeczy'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = df_eco.reset_index().drop(columns='id').rename(columns={'Unnamed: 0': 'id'}).set_index('id')\n",
        "df_eco = df_eco[df_eco['date'] < datetime(2023, 1, 1)]\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wprost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'wprost'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Newsweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'newsweek'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## wPolityce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'wpolityce'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "corps = [file for file in os.listdir() if file.startswith(\"eco\")]\n",
        "print(corps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Most Common ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat(data)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from files.ngram.ngrams import ngram_counter\n",
        "df = df[~df['clean_text'].isna()]\n",
        "for ngram in range(1, 4):\n",
        "    df_ngram = ngram_counter(ngram, df).iloc[:100]\n",
        "    df_ngram.to_csv(f\"most_common_{ngram}-gram.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt\n",
        "x = df_ngram.index\n",
        "y = df_ngram[1]\n",
        "# Define the function to fit\n",
        "def func(x, A, B, C):\n",
        "    return A * np.power(x, B) + C\n",
        "\n",
        "# Fit the data\n",
        "params, _ = curve_fit(func, x, y)\n",
        "\n",
        "# Extract the fitted parameters\n",
        "A, B, C = params\n",
        "\n",
        "# Print the fitted parameters\n",
        "print(f\"A: {A}, B: {B}, C: {C}\")\n",
        "y = df_ngram[1] \n",
        "plt.plot(df_ngram[1])\n",
        "plt.plot(func(x, A, B, C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selected ngrams distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import regex as re\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = []\n",
        "for corp in corps:\n",
        "    df = pd.read_csv(corp, usecols=['clean_text','date', 'source'], parse_dates=['date'])\n",
        "    data.append(df)\n",
        "    \n",
        "data = pd.concat(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['climate_change_count'] = data['clean_text'].str.count(r\"zmiana klimat\", flags=re.IGNORECASE)\n",
        "data['global_warming_count'] = data['clean_text'].str.count(r\"globalny ocieplenie\", flags=re.IGNORECASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_warming_count = data.groupby(data.date.dt.year).global_warming_count.sum()\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(global_warming_count.index, global_warming_count)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of mentions\")\n",
        "plt.title(\"How many times 'globalny ocieplenie' appeared in the lemmatized text in a given year\")\n",
        "plt.savefig(\"global_warming.png\")\n",
        "plt.xlabel(\"Year\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "climate_change_count = data.groupby(data.date.dt.year).climate_change_count.sum()\n",
        "#climate_change_count = data.groupby(pd.Grouper(key='date', freq='M')).climate_change_count.sum()\n",
        "plt.bar(climate_change_count.index, climate_change_count)\n",
        "plt.suptitle(\"How many times 'zmiana klimat' appeared in the lemmatized text in a given a month\", fontsize=15)\n",
        "plt.ylabel(\"Number of mentions\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.savefig(\"climate_change.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
