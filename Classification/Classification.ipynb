{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from classify import data_pipeline, eco_selector\n",
        "from resources.get_data import get_current_data\n",
        "from resources.setup import get_setup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validator(df):\n",
        "    df = df.drop_duplicates()\n",
        "    df = df[~df['text'].isna()]\n",
        "    if 'vectorized' in df.columns.values:\n",
        "        df = df.drop(columns=['vectorized'])\n",
        "    if df.index.duplicated().any():\n",
        "        print(\"Duplicated index!!!\")\n",
        "        df = df.reset_index()\n",
        "        df = df.drop(columns = ['id'])\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    print(f\"Found {len(df)} files\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rzepa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'rzepa'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_final = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wyborcza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'wyborcza'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_final = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gazeta Polska Codziennie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "gpc\n",
            "Configuration finished\n",
            "Dataset of 7471 samples\n",
            "label\n",
            "1    4128\n",
            "0    3343\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9986631016042781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:29<00:00,  1.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11504 1149\n",
            "Duplicated index!!!\n",
            "Found 3278 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'gpc'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polityka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "polityka\n",
            "Configuration finished\n",
            "Dataset of 11849 samples\n",
            "label\n",
            "1    8700\n",
            "0    3149\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9873417721518988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:12<00:00,  3.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1909 220\n",
            "Found 754 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'polityka'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Small Corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dorzeczy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "dorzeczy\n",
            "Configuration finished\n",
            "Dataset of 11342 samples\n",
            "label\n",
            "1    8400\n",
            "0    2942\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9947136563876652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "696 76\n",
            "Found 242 files\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "corp = 'dorzeczy'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = df_eco.reset_index().drop(columns='id').rename(columns={'Unnamed: 0': 'id'}).set_index('id')\n",
        "df_eco = df_eco[df_eco['date'] < datetime(2023, 1, 1)]\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wprost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wprost\n",
            "Configuration finished\n",
            "Dataset of 5279 samples\n",
            "label\n",
            "0    2911\n",
            "1    2368\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9867424242424242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "550 34\n",
            "Duplicated index!!!\n",
            "Found 402 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wprost'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicated index!!!\n",
            "Found 342 files\n"
          ]
        }
      ],
      "source": [
        "df_eco = pd.concat([df_eco, df_rest.drop(index=2260)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Newsweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "newsweek\n",
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "newsweek\n",
            "Configuration finished\n",
            "Dataset of 11417 samples\n",
            "label\n",
            "1    8452\n",
            "0    2965\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.989492119089317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:05<00:00,  2.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "933 104\n",
            "Duplicated index!!!\n",
            "Found 390 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'newsweek'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## wPolityce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wpolityce\n",
            "Configuration finished\n",
            "Dataset of 5298 samples\n",
            "label\n",
            "0    2962\n",
            "1    2336\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9924528301886792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:23<00:00,  7.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1362 76\n",
            "Found 413 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wpolityce'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['eco_gpc.csv', 'eco_wyborcza.csv', 'eco_rzepa.csv', 'eco_polityka.csv', 'eco_dorzeczy.csv', 'eco_wprost.csv', 'eco_newsweek.csv', 'eco_wpolityce.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "corps = [file for file in os.listdir() if file.startswith(\"eco\")]\n",
        "print(corps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eco_gpc.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eco_wyborcza.csv\n",
            "eco_rzepa.csv\n",
            "eco_polityka.csv\n",
            "eco_dorzeczy.csv\n",
            "eco_wprost.csv\n",
            "eco_newsweek.csv\n",
            "eco_wpolityce.csv\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for corp in corps:\n",
        "    print(corp)\n",
        "    data.append(pd.read_csv(corp, usecols=['clean_text']))\n",
        "\n",
        "df = pd.concat(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from files.ngram.ngrams import ngram_counter\n",
        "df = df[~df['clean_text'].isna()]\n",
        "for ngram in range(1, 4):\n",
        "    df_ngram = ngram_counter(ngram, df).iloc[:100]\n",
        "    df_ngram.to_csv(f\"most_common_{ngram}-gram.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
