{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from classify import data_pipeline, eco_selector\n",
        "from resources.get_data import get_current_data\n",
        "from resources.setup import get_setup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validator(df):\n",
        "    df = df.drop_duplicates()\n",
        "    df = df[~df['text'].isna()]\n",
        "    if 'vectorized' in df.columns.values:\n",
        "        df = df.drop(columns=['vectorized'])\n",
        "    if df.index.duplicated().any():\n",
        "        print(\"Duplicated index!!!\")\n",
        "        df = df.reset_index()\n",
        "        df = df.drop(columns = ['id'])\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    print(f\"Found {len(df)} files\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rzepa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "rzepa\n",
            "Configuration finished\n",
            "Dataset of 14070 samples\n",
            "label\n",
            "0    8464\n",
            "1    5606\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9964463397299218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44/44 [00:59<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21962 665\n",
            "Found 6271 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'rzepa'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wyborcza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wyborcza\n",
            "Configuration finished\n",
            "Dataset of 5601 samples\n",
            "label\n",
            "0    3000\n",
            "1    2601\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9910873440285205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [01:25<00:00,  3.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13316 1323\n",
            "Duplicated index!!!\n",
            "Found 2924 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wyborcza'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gazeta Polska Codziennie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "gpc\n",
            "Configuration finished\n",
            "Dataset of 5842 samples\n",
            "label\n",
            "0    3000\n",
            "1    2842\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9880341880341881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7498 1235\n",
            "Duplicated index!!!\n",
            "Found 3077 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'gpc'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polityka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "polityka\n",
            "Configuration finished\n",
            "Dataset of 17765 samples\n",
            "label\n",
            "0    9097\n",
            "1    8668\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9926842993809791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:05<00:00,  1.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1046 156\n",
            "Found 658 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'polityka'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Small Corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dorzeczy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "corp = 'dorzeczy'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = df_eco.reset_index().drop(columns='id').rename(columns={'Unnamed: 0': 'id'}).set_index('id')\n",
        "df_eco = df_eco[df_eco['date'] < datetime(2023, 1, 1)]\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wprost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wprost\n"
          ]
        }
      ],
      "source": [
        "corp = 'wprost'\n",
        "configuration = get_setup(corp)\n",
        "df_eco, df_non_eco, df_rest = get_current_data(configuration)\n",
        "df_eco = pd.concat([df_eco, df_rest.drop(index=2260)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Newsweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "newsweek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ps/Code/Climate/Classification/resources/get_data.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_rest = pd.read_csv(drive_path / corpus / \"results.csv\", index_col = ['id', 'source'], parse_dates=['date'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicated index!!!\n",
            "Found 378 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'newsweek'\n",
        "configuration = get_setup(corp)\n",
        "df_eco, df_non_eco, df_rest = get_current_data(configuration)\n",
        "df_all = pd.concat([df_rest.drop(index=2051), df_eco])\n",
        "df_eco = validator(df_eco)\n",
        "df_all.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## wPolityce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wpolityce\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ps/Code/Climate/Classification/resources/get_data.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_eco = pd.read_csv(drive_path / corpus / \"eco_result.csv\", index_col=['id', 'source'], parse_dates=['date'])\n",
            "/home/ps/Code/Climate/Classification/resources/get_data.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_non_eco = pd.read_csv(drive_path / corpus / \"non_eco_result.csv\", index_col = ['id', 'source'], parse_dates=['date'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicated index!!!\n",
            "Found 398 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wpolityce'\n",
        "configuration = get_setup(corp)\n",
        "df_eco, df_non_eco, df_rest = get_current_data(configuration)\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['eco_gpc.csv', 'eco_wyborcza.csv', 'eco_rzepa.csv', 'eco_polityka.csv', 'eco_dorzeczy.csv', 'eco_wprost.csv', 'eco_newsweek.csv', 'eco_wpolityce.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "corps = [file for file in os.listdir() if file.startswith(\"eco\")]\n",
        "print(corps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eco_gpc.csv\n",
            "eco_wyborcza.csv\n",
            "eco_rzepa.csv\n",
            "eco_polityka.csv\n",
            "eco_dorzeczy.csv\n",
            "eco_wprost.csv\n",
            "eco_newsweek.csv\n",
            "eco_wpolityce.csv\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for corp in corps:\n",
        "    print(corp)\n",
        "    data.append(pd.read_csv(corp, usecols=['text']))\n",
        "\n",
        "df = pd.concat(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ZRÓWNOWAŻONY ROZWÓJ \\ Jak pokazują badania, aż...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENERGETYKA \\ Trzy magazyny energii elektryczne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transformacja energetyczna to zarówno potężne ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ministrowie ds. energii Unii Europejskiej usta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Są? dwie dobre wiadomości dla odbiorców gazu i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>Zielony (nie)ładKomisja Europejska uważa, że p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>Jesteśmy krajem bezpiecznym pod względem żywno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>1 czerwca imigranci z Bliskiego Wschodu, Afryk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>Amerykański renomowany bank Goldman Sachs poda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>W czasie pandemii rzuciłem się na seriale w ne...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12982 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "0    ZRÓWNOWAŻONY ROZWÓJ \\ Jak pokazują badania, aż...\n",
              "1    ENERGETYKA \\ Trzy magazyny energii elektryczne...\n",
              "2    Transformacja energetyczna to zarówno potężne ...\n",
              "3    Ministrowie ds. energii Unii Europejskiej usta...\n",
              "4    Są? dwie dobre wiadomości dla odbiorców gazu i...\n",
              "..                                                 ...\n",
              "393  Zielony (nie)ładKomisja Europejska uważa, że p...\n",
              "394  Jesteśmy krajem bezpiecznym pod względem żywno...\n",
              "395  1 czerwca imigranci z Bliskiego Wschodu, Afryk...\n",
              "396  Amerykański renomowany bank Goldman Sachs poda...\n",
              "397  W czasie pandemii rzuciłem się na seriale w ne...\n",
              "\n",
              "[12982 rows x 1 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
