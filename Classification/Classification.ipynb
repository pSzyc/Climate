{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from classify import data_pipeline, eco_selector\n",
        "from resources.get_data import get_current_data\n",
        "from resources.setup import get_setup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validator(df):\n",
        "    df = df.drop_duplicates()\n",
        "    df = df[~df['text'].isna()]\n",
        "    if 'vectorized' in df.columns.values:\n",
        "        df = df.drop(columns=['vectorized'])\n",
        "    if df.index.duplicated().any():\n",
        "        df = df.reset_index()\n",
        "        df = df.drop(columns = ['id'])\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    print(f\"Found {len(df)} files\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rzepa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'rzepa'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wyborcza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'wyborcza'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gazeta Polska Codziennie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'gpc'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polityka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'polityka'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Small Corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dorzeczy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp = 'dorzeczy'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wprost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wprost\n",
            "Found 445 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wprost'\n",
        "configuration = get_setup(corp)\n",
        "df_eco, df_non_eco, df_rest = get_current_data(configuration)\n",
        "df_eco = pd.concat([df_eco, df_rest.drop(index=2260)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Newsweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "newsweek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ps/Code/Climate/Classification/resources/get_data.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_rest = pd.read_csv(drive_path / corpus / \"results.csv\", index_col = ['id', 'source'], parse_dates=['date'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 378 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'newsweek'\n",
        "configuration = get_setup(corp)\n",
        "df_eco, df_non_eco, df_rest = get_current_data(configuration)\n",
        "df_all = pd.concat([df_rest.drop(index=2051), df_eco])\n",
        "df_eco = validator(df_eco)\n",
        "df_all.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## wPolityce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wpolityce\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ps/Code/Climate/Classification/resources/get_data.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_eco = pd.read_csv(drive_path / corpus / \"eco_result.csv\", index_col=['id', 'source'], parse_dates=['date'])\n",
            "/home/ps/Code/Climate/Classification/resources/get_data.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_non_eco = pd.read_csv(drive_path / corpus / \"non_eco_result.csv\", index_col = ['id', 'source'], parse_dates=['date'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 398 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wpolityce'\n",
        "configuration = get_setup(corp)\n",
        "df_eco, df_non_eco, df_rest = get_current_data(configuration)\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
